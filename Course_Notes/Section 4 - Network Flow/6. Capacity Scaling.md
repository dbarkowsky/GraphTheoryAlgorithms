Really a heuristic, not algorithm.

Prioritize taking edges with the higher capacity. 

U = value of largest edge capacity in initial flow graph
D = the largest power of 2 <= U

So, capacity scaling says:
- only take edges whose remaining capacity is >= D.
Should result in a better overall runtime, as it's not wasting time with smaller flows only to update them later. They will eventually have this bigger max flow, why not get to it as soon as possible?

But eventually no paths will satisfy that check.
In that case, D now equals D / 2 and repeat process while D is > 0.

This works very well in practice, with closer to logarithmic time complexity.

In the end, this is just the [[1. Max Flow - Ford Fulkerson]] but with priority on which edges it travels.